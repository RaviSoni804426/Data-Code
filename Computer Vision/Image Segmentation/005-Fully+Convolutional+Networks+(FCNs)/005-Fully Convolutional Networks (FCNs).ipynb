{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1mNCwzWdqJ2C8GWfjCdlG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Fully Convolutional Networks (FCNs)\n","![](https://drive.google.com/uc?id=1jaU0zy7djT0W698uLp80OMNWkEYSa_CR)"],"metadata":{"id":"Wz868OUYiPj2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"lB_v2n2QiH3L","executionInfo":{"status":"ok","timestamp":1742058730865,"user_tz":-330,"elapsed":11313,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["import torchvision.models as models\n","vgg = models.vgg16(pretrained=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5VKFsZ4ymFA","executionInfo":{"status":"ok","timestamp":1742062568809,"user_tz":-330,"elapsed":1738,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"6e15734d-e5e7-49fd-ade7-9b841ebf0415"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["# pool3\n","# pool4\n","# final-output"],"metadata":{"id":"srwCjTOGy5AK","executionInfo":{"status":"ok","timestamp":1742058826405,"user_tz":-330,"elapsed":11,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary"],"metadata":{"id":"oXJ8j6SZzClZ","executionInfo":{"status":"ok","timestamp":1742058845428,"user_tz":-330,"elapsed":7,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["summary(vgg, (3, 224, 224))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9OtuCoxzHPx","executionInfo":{"status":"ok","timestamp":1742058878482,"user_tz":-330,"elapsed":2333,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"ecf80ee2-7a15-4774-d801-f248f6c7a987"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           1,792\n","              ReLU-2         [-1, 64, 224, 224]               0\n","            Conv2d-3         [-1, 64, 224, 224]          36,928\n","              ReLU-4         [-1, 64, 224, 224]               0\n","         MaxPool2d-5         [-1, 64, 112, 112]               0\n","            Conv2d-6        [-1, 128, 112, 112]          73,856\n","              ReLU-7        [-1, 128, 112, 112]               0\n","            Conv2d-8        [-1, 128, 112, 112]         147,584\n","              ReLU-9        [-1, 128, 112, 112]               0\n","        MaxPool2d-10          [-1, 128, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]         295,168\n","             ReLU-12          [-1, 256, 56, 56]               0\n","           Conv2d-13          [-1, 256, 56, 56]         590,080\n","             ReLU-14          [-1, 256, 56, 56]               0\n","           Conv2d-15          [-1, 256, 56, 56]         590,080\n","             ReLU-16          [-1, 256, 56, 56]               0\n","        MaxPool2d-17          [-1, 256, 28, 28]               0\n","           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n","             ReLU-19          [-1, 512, 28, 28]               0\n","           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n","             ReLU-21          [-1, 512, 28, 28]               0\n","           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n","             ReLU-23          [-1, 512, 28, 28]               0\n","        MaxPool2d-24          [-1, 512, 14, 14]               0\n","           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n","             ReLU-26          [-1, 512, 14, 14]               0\n","           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n","             ReLU-28          [-1, 512, 14, 14]               0\n","           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n","             ReLU-30          [-1, 512, 14, 14]               0\n","        MaxPool2d-31            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 218.78\n","Params size (MB): 527.79\n","Estimated Total Size (MB): 747.15\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"8D-L5x841ehJ","executionInfo":{"status":"ok","timestamp":1742059478527,"user_tz":-330,"elapsed":3,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class FCN8(nn.Module):\n","  def __init__(self, num_classes=2):\n","    super(FCN8, self).__init__()\n","    vgg = models.vgg16(pretrained=True)\n","    self.features = vgg.features # till convolution and pooling layers\n","\n","    # extract intermediate feature maps\n","    self.pool3 = self.features[:17]\n","    self.pool4 = self.features[:24]\n","    self.pool5 = self.features\n","\n","    # 1x1 convolutions to convert to class scores\n","    self.conv1x1_3 = nn.Conv2d(256, num_classes, kernel_size=1)\n","    self.conv1x1_4 = nn.Conv2d(512,num_classes, kernel_size=1)\n","    self.conv1x1_5 = nn.Conv2d(512, num_classes, kernel_size=1)\n","\n","    self.upsample32 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1)\n","    self.upsample16 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, padding=1)\n","    self.upsample8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=16, stride=8, padding=4)\n","\n","  def forward(self, x):\n","    pool3_out = self.pool3(x)\n","    pool4_out = self.pool4(x)\n","    pool5_out = self.pool5(x)\n","\n","    pool3_out = self.conv1x1_3(pool3_out)\n","    pool4_out = self.conv1x1_4(pool4_out)\n","    pool5_out = self.conv1x1_5(pool5_out)\n","\n","    x = self.upsample32(pool5_out) + pool4_out\n","    x = self.upsample16(x) + pool3_out\n","    x = self.upsample8(x)\n","\n","    return x\n"],"metadata":{"id":"amE4PWjqzOwJ","executionInfo":{"status":"ok","timestamp":1742062573160,"user_tz":-330,"elapsed":7,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# I = \"input size\"\n","# S = \"Stride\"\n","# K = \"Kernel Size\"\n","# P = \"Padding\"\n","# O = (I - 1) * S + K - 2*P\n","\n","# input_size = 224, 224\n","# max_pool5 = 7, 7 == 32x\n","# max_pool4 = 14, 14 == 16x\n","# max_pool3 = 28, 28 == 8x"],"metadata":{"id":"xQ2pbmwy78TS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["224/7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1w8rSn_83_y","executionInfo":{"status":"ok","timestamp":1742061444043,"user_tz":-330,"elapsed":13,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"062de062-8b9d-43b7-dbbd-596e912db140"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32.0"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# dummy input\n","model = FCN8(num_classes=1000)\n","dummy_input = torch.randn(1,3, 224, 224)\n","output = model(dummy_input)\n","print(\"Output shape : \", output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqVE-yll85-M","executionInfo":{"status":"ok","timestamp":1742062614682,"user_tz":-330,"elapsed":20951,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"5ec55bdd-8aa0-45d3-b9ee-a15174bac47a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape :  torch.Size([1, 1000, 224, 224])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VJ9gnd5UA8Fv"},"execution_count":null,"outputs":[]}]}